---
title: "Fed Chronicles -> The Upside Down"
date: 2021-12-07T21:13:14-05:00
draft: false
---
&nbsp;
&nbsp;

When the Fed announced its new policy framework in August 2020, it did so believing the update to its approach would help it address over a decade of anemic, low inflation. After such a long period of relatively stable prices, at that point Jay Powell and crew likely didn't think it would only be a matter of months until they would face levels of inflation unseen in 30 years. 

The question has since flipped from whether the new framework can succeed where policy guidance in the 2010s failed in buoying inflation to whether it can do the exact opposite, containing inflation before it stays too high for too long. The FOMC has pivoted abruptly on the pace of tapering after getting spooked by recent inflation readings, and I'll describe why this isn't actually an abandonment of the new framework and what that framework means for 2022.

The chart below shows the reversal in the most daunting problem to solve to achieve the Fed's dual mandate. It used to be that inflation couldn't get above 2% no matter how tight the labor market got, and now it's that inflation is far above 2% though the labor market has room to tighten. The Fed has been thrust into an alternate dimension, the Upside Down, where a demogorgon named 'supply chain bottlenecks' hangs out. 

```{r setup, include=FALSE}
library(tidyverse)
library(gganimate)
library(stringr)
library(scales)
library(splitstackshape)
library(quantmod)
library(lubridate)
library(blscrapeR)
library(tibbletime)

windowsFonts("Open Sans" = windowsFont("Open Sans"))
windowsFonts("Open Sans Light" = windowsFont("Open Sans Light"))

knitr::opts_chunk$set(echo = TRUE)


colors <- c('paleblue' = "#a6cee3", 'blue' = "#1f78b4", 'green' = "#33a02c", 'palegreen' = "#b2df8a",
            'red' = "#e31a1c", 'palered' = "#fb9a99", 'orange' = "#ff7f00", 'paleorange' = "#fdbf6f",
            'purple' = "#6a3d9a", 'palepurple' = "#cab2d6", 'border grey' = "#808080", 'brown' = '#b15928',
            'text' = "#222222" , 'light grey' = "#CDCDCD")

cpal <- function(...) {
  cols <- c(...)
  if (is.null(cols))
    return(colors)
  colors[[cols]]
}


my_theme <- theme(
    legend.position = "bottom",
    legend.title = element_blank(),
    legend.key = element_blank(),
    legend.key.size = unit(0.37, "cm"),
    legend.background = element_blank(),
    legend.margin = margin(t = -0.5, unit = "cm"),
    panel.background = element_rect(fill = "white"),
    panel.grid.major = element_line(color = cpal("light grey"), size = 0.21),
    panel.border = element_rect(fill = NA, color = cpal("border grey"), size = 0.3),
    plot.title = element_text(size = 21, color = "black", family = "Open Sans Light"),
    plot.subtitle = element_text(size = 14, color = cpal("text"), family = "Open Sans"),
    plot.caption = element_text(size = 12.5, color = cpal("text"), family = "Open Sans"),
    text = element_text(size = 15, color = cpal("text"), family = "Open Sans"),
    legend.text = element_text(size = 14, color = cpal("text"), family = "Open Sans"),
    axis.text.x = element_text(size = 14, color = cpal("text"), family = "Open Sans",
                               margin = unit(c(0.35, 0.25, 0.25, 0.25), "cm")),
    axis.text.y = element_text(size = 14, color = cpal("text"), family = "Open Sans",
                               margin = unit(c(0.35, 0.25, 0.25, 0.25), "cm")),
    axis.title.y = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.length = unit(-0.15, "cm"),
    axis.ticks = element_line(color = cpal("border grey"), size = 0.3),
    plot.margin = unit(c(0.3, 0.5, 0.3, 0.05), "cm")
  )

```



```{r echo=FALSE, warning=FALSE, message = FALSE, tidy=FALSE}
raw_dat <- getSymbols(c("LNS12300060", "PCEPILFE", "FEDFUNDS"), 
                      src='FRED', auto.assign=T) 



ctitle_1 <- "Inflation, employment, and Fed Funds conditions"
source_1 <- "Quarterly data. FF = Fed Funds Rate. Source: BLS, BEA, FRED, @benbakkum."


merge(LNS12300060, PCEPILFE, FEDFUNDS) %>% 
  as.data.frame() %>% 
  rownames_to_column() %>% 
  rename(date = rowname) %>% 
  mutate(date = as.Date(date, "%Y-%m-%d")) %>% 
  na.omit() %>% 
  set_names("date", "epop", "pce", "FF") %>% 
  mutate(pce = (pce / lag(pce, 12) - 1) * 100,
         period = case_when(str_sub(year(date),3,3) == "9" ~ "'90s",
                            str_sub(year(date),3,3) == "0" ~ "'00s",
                            str_sub(year(date),3,4) <  15 ~ "'10 - '14",
                            str_sub(year(date),3,4) <  20 ~ "'15 - '19",
                            str_sub(year(date),3,3) == "2" ~ "'20 - '21"),
         placeholder = "x",
         date_txt = ifelse(date == "2021-06-01","Q2 '21",
                           ifelse(date == "2021-09-01", "Q3 '21", NA_real_))) %>% 
  filter(date > "2009-12-31",
         month(date) == 3 |
         month(date) == 6 |
         month(date) == 9 |
         month(date) == 12) %>% 
  ggplot(aes(epop, pce, color = FF, shape = period)) +
  geom_point(size = 5, alpha = .5) +
  geom_text(aes(epop, pce, label = date_txt),
            hjust = 0, vjust = 2.5, size = 4.2)+
  scale_y_continuous(limits = c(0,4), expand = c(0,0)) +
  theme(
    legend.background = element_blank(),
    panel.background = element_rect(fill = "white"),
    panel.grid.major = element_line(color = cpal("light grey"), size = 0.21),
    panel.border = element_rect(fill = NA, color = cpal("border grey"), size = 0.3),
    plot.title = element_text(size = 18, color = "black", family = "Open Sans Light"),
    plot.subtitle = element_text(size = 14, color = cpal("text"), family = "Open Sans"),
    plot.caption = element_text(size = 12.5, color = cpal("text"), family = "Open Sans"),
    text = element_text(size = 15, color = cpal("text"), family = "Open Sans"),
    legend.text = element_text(size = 14, color = cpal("text"), family = "Open Sans"),
    axis.text.x = element_text(size = 14, color = cpal("text"), family = "Open Sans",
                               margin = unit(c(0.35, 0.25, 0.25, 0.25), "cm")),
    axis.text.y = element_text(size = 14, color = cpal("text"), family = "Open Sans",
                               margin = unit(c(0.35, 0.25, 0.25, 0.25), "cm")),
    axis.title.y = element_text(size = 14, color = cpal("text"), family = "Open Sans"),
    axis.title.x = element_text(size = 14, color = cpal("text"), family = "Open Sans"),
    axis.ticks.length = unit(-0.15, "cm"),
    axis.ticks = element_line(color = cpal("border grey"), size = 0.3),
    plot.margin = unit(c(0.3, 0.5, 0.3, 0.05), "cm")
  ) +
  guides(shape = guide_legend(title = "Period")) +
  labs(x = "Prime-age Employment-to-Population Ratio. %",
       y = "Core PCE prices, % year-over-year", 
       title = ctitle_1, 
       caption = source_1) +
  transition_manual(placeholder) -> p



anim1 <- animate(p, renderer = gifski_renderer(loop = T), nframe = 1,
                 width = 615, height = 420, type = "cairo")

anim1
 
```

There's pretty precise language in the announcement of the average inflation targeting framework for how to deal with conflicting signals coming from the inflation and employment parts of the mandate. There's also an explicit test the Fed has laid out for economic conditions to pass before it will hike rates. I think two additional concepts or themes, however, are key for understanding why the Fed is doing what it's doing now and for anticipating what it will do in 2022. Those two things are (1) uncertainty and (2) asymmetry.  

The thing the Fed is certain of right now is that the labor market is improving, but it still has room to go before it has fully recovered, and the Fed doesn't want to unnecessarily slow that improvement. The Fed is uncertain of how long inflation will remain uncomfortably high. Importantly, the recent hawkish tilt related to accelerating the tapering of asset purchases and slowing the growth of the Fed's balance sheet (shown below) is less about tightening than it is expanding the optionality in terms of timing to tighten as uncertainty around the persistence of inflation wanes going forward. Powell often notes that the stock of assets held by the Fed provides the accommodation, so any further purchases serve as incremental accommodation. It's not tightening, it's just less additional easing.


```{r echo=FALSE, warning=FALSE, message = FALSE, tidy=FALSE}
raw_dat <- getSymbols(c('WALCL', 'WSHOTSL', 'WSHOMCB', "H41RESPPAAC2HNWW",
                        "H41RESPPAABNWW", "H41RESPPAAENWW", "H41RESPPAADHNWW",
                        "H41RESPPAATAL2HNWW", "SWPT", "WLTLECL", "WLFN", "WLRRAL", "WLDLCL", "WCTCL"), 
                      src='FRED', auto.assign=T) 


dat <- merge(WALCL, WSHOTSL, WSHOMCB, H41RESPPAAC2HNWW, H41RESPPAABNWW, H41RESPPAAENWW, H41RESPPAADHNWW,
      H41RESPPAATAL2HNWW, SWPT, WLTLECL, WLFN, WLRRAL, WLDLCL, WCTCL) %>% 
  as.data.frame() %>% 
  rownames_to_column() %>% 
  rename(date = rowname,
         total_assets = WALCL,
         USTs = WSHOTSL,
         MBS = WSHOMCB,
         CPFF = H41RESPPAAC2HNWW,
         CCF = H41RESPPAABNWW,
         MSLP = H41RESPPAAENWW,
         MLF = H41RESPPAADHNWW,
         TALF = H41RESPPAATAL2HNWW,
         liquidity_swaps = SWPT,
         total_liabilities = WLTLECL,
         fed_reserve_notes = WLFN,
         reverse_repo = WLRRAL,
         deposits = WLDLCL,
         total_capital = WCTCL) %>% 
  mutate(date = as.Date(date, "%Y-%m-%d"),
         facilities = (CPFF + CCF + MSLP + MLF + TALF),
         other_assets = (total_assets - USTs - MBS - facilities - liquidity_swaps),
         other_liabilities = (total_liabilities - fed_reserve_notes - reverse_repo - deposits),
         balances = (USTs + MBS + facilities + liquidity_swaps + other_assets) ==
                    (fed_reserve_notes + reverse_repo + deposits + other_liabilities + total_capital),
         fed_reserve_notes = -fed_reserve_notes,
         reverse_repo = -reverse_repo,
         deposits = -deposits,
         other_liabilities = -other_liabilities,
         total_capital = -total_capital) %>% 
  filter(date > "2007-12-31") %>% 
  select(date, USTs, MBS, facilities, liquidity_swaps, other_assets,
         fed_reserve_notes, reverse_repo, deposits, other_liabilities, total_capital) %>% 
  pivot_longer(USTs:total_capital, names_to = "key", values_to = "values") %>% 
  mutate(key = case_when(key == "USTs" ~ "USTs",
                         key == "MBS" ~ "MBS",
                         key == "facilities" ~ "2020 facilities",
                         key == "other_assets" ~ "Other assets",
                         key == "fed_reserve_notes" ~ "Federal Reserve Notes",
                         key == "reverse_repo" ~ "Reverse repo",
                         key == "deposits" ~ "Deposits",
                         key == "liquidity_swaps" ~ "Liquidity swaps",
                         key == "other_liabilities" ~ "Other liabilities", 
                         key == "total_capital" ~ "Total Capital"),
         key = ordered(key, c("2020 facilities", "Liquidity swaps", "Other assets", 
                              "MBS", "USTs", "Total Capital", 
                              "Reverse repo", "Other liabilities",
                              "Deposits", "Federal Reserve Notes" 
                              )))

fills <-  c(
            "2020 facilities" = "#053061",
            "Liquidity swaps" = "#2166ac",
            "Other assets" = "#4393c3",
            "MBS" = "#92c5de",
            "USTs" = "#bbddf0",
          #  "label here" = "#cee5f2",
          #  "label here" = "#f7c9ad",
            "Federal Reserve Notes" = "#ffd0a1",
            "Deposits" = "#ffaf5e",
            "Other liabilities" = "#ff7f00",
            "Reverse repo" = "#d16800",
            "Total Capital" = "#ab5500"
            )


ctitle_1 <- "The Federal Reserve's balance sheet"
unit_label <- "Billions, $"
source_1 <- "Source: Federal Reserve, @benbakkum."

fmt_dcmls_abs <- function(decimals = 0) {
  function(x) as.character(format(round(abs(as.numeric(x)), 0), nsmall=0, big.mark=","))
}


bs_chart <- dat %>% 
  ggplot(aes(x = date, y = values / 1000, fill = key)) +
  geom_area() +
  scale_fill_manual(values = fills) +
  scale_x_date(expand = c(0,0),
               date_breaks = "1 year",
               date_labels = "'%y") +
  scale_y_continuous(expand = c(0,0),
                     labels = fmt_dcmls_abs(),
                     breaks = pretty_breaks(8)) +
  my_theme +
  theme(
    panel.grid.minor = element_blank(),
    plot.margin = unit(c(0.3, 0.5, 0.3, 0.4), "cm"),
    legend.margin = margin(t = 0.3, unit = "cm"),
    legend.text = element_text(size = 14, color = cpal("text"), family = "Open Sans")
  ) +
  guides(fill=guide_legend(ncol = 2,bycol=TRUE)) +
  labs(title = ctitle_1, subtitle = unit_label, caption = source_1) +
  transition_reveal(date) +
  view_follow()

anim <- animate(bs_chart, renderer = gifski_renderer(loop = T), fps = 25, duration = 15,
                 width = 650, height = 560, type = "cairo", end_pause = 120)

anim 
```
The Fed essentially still wants to give itself time to see if inflation declines in the first half of next year, after enough time will have been given for supply and demand imbalances to fade in the wake of the Delta wave. I am doubtful that the Fed wants to tie a rate hike directly to the end of tapering, instead giving time for conditions to evolve with the end of QE, so I would expect that the accelerated taper will end in the spring and the first hike would come late in the summer at the earliest, with a second 2022 hike coming at the end of the year if at all. This is speculative, however, and may be underestimating the extent of the fresh hawkish sentiment on the Committee right now. 

The other factor I mentioned that's at play is asymmetry, and I think it manifests in (1) asymmetry in the Fed's ability to steer the inflation side of its mandate relative to shaping the employment side at this point in time and (2) asymmetry in the Fed's ability over the longer-term to keep a lid on inflation relative to its ability to push it higher when it's too low. 

On the first count, it seems to me that monetary policymakers are quite aware of their own limitations in this specific situation. The large bulk of the pickup in inflation of the last year has come on the back of core goods prices, suggesting much may be due to the pandemic's effects. It's unclear how much a marginally higher Fed Funds rate would alleviate this kind of inflationary pressure, while it's possible to have greater confidence that tighter financial conditions would adversely slow employment growth. 

I think SF Fed President Mary Daly summarized this view well back in mid-November, which I doubt has changed even despite all the taper talk:

> Monetary policy is a blunt tool that acts with a considerable lag. So, raising interest rates today would do little to increase production, fix supply chains, or stop consumers from spending more on goods than on services.
But it would curb demand 12 to 18 months from now. Should current high inflation readings and worker shortages turn out to be COVID-related and transitory, higher interest rates would bridle growth, slow recovery in the labor market and unnecessarily sideline millions of workers.
Against this calculus, I come down on the side of waiting to gain greater clarity. The Fed is well positioned to act should inflation begin to look more persistent. It’s much harder to unwind a preemptive action that turns out to be wrong.

Powell's thinking also likely still reflects this view, as he described in late October:

> It would be premature to tighten policy by raising rates now with the effect and intent of slowing job growth when there's good reason to expect robust job growth and for these supply constraints to diminish, both of which would have the effect of increasing the potential output of the economy.
Effectively we're missing a piece of potential output because of the supply constraints and the non-full reopening of the service sector, so we want to give full time for that to come back before we start restraining demand with interest rate increases.

The second asymmetry concerns the varying difficulties the Fed faces in trying to prod tepid inflation higher versus attempting to muscle elevated inflation lower. Fed Governor Lael Brainard notes that "while the playbook for guiding inflation back down to target following a moderate overshoot is well tested and effective, experience suggests it is difficult to guide inflation up to target from below." This dynamic can be attributed in large part to the zero lower bound. Outgoing Governor Randy Quarles also said in a recent speech that "The inability to cut interest rates sufficiently can then reinforce downward pressures on inflation such that it begins to run persistently below the FOMC's 2 percent goal and causes inflation expectations to fall with it."

When you perceive that it's harder to reach your 2% target from below than from above, you will err on the side of not risking an overreaction to inflation above target and returning it to permanently below 2%. With these uncertainties and asymmetries in mind, let's circle back to the new framework and what it says about when both sides of the Fed's mandate conflict. The 2020 Statement on Longer-Run Goals and Monetary Policy Strategy includes that in such a situation the Committee "takes into account the employment shortfalls and inflation deviations and the potentially different time horizons over which employment and inflation are projected to return to levels judged consistent with its mandate."

What matters when inflation and employment give different signals for how policy should be positioned is (1) how far inflation is from 2% and how far the labor market is from full employment and (2) how long it seems like it will take them to get there. My impression is that all roads lead to mid-2022. Next summer, the labor market will likely have reached something that could be roughly described as full employment, and we will know by that point if the bulk of the recent updraft in inflation had rolled off. My proxy of conditions on the labor side that I base that expectation on is the prime-age employment-to-population ratio, which looks on track to reach its pre-pandemic level by mid-next year.

```{r echo=FALSE, warning=FALSE, message = FALSE, tidy=FALSE}

raw_dat <- bls_api(c("LNS12300060"), 
              startyear = 2005, 
              endyear = 2021,
              Sys.getenv("BLS_KEY")) 

data.frame(name = c("EPOP"),
           code = c("LNS12300060")) -> key


raw_dat %>% 
  mutate(date = paste0(periodName, " ", year, " 01"),
         date = as.Date(date, "%B %Y %d")) %>% 
  rename(code = seriesID) %>% 
  left_join(key, by = "code") %>% 
  select(value, date, name) %>% 
  pivot_wider(names_from = "name", values_from = "value") %>% 
  arrange(date) %>% 
  mutate(since_feb20 = case_when(date == ymd("2020-02-01") ~ EPOP,
                                 date != ymd("2020-02-01") ~ NA_real_),
         since_now =   case_when(date == ymd("2021-11-01") ~ EPOP, #edit this
                                 date != ymd("2021-11-01") ~ NA_real_)) -> dat #edit this


data.frame(date = month_dates <- seq(tail(dat$date,1) %m+% months(1), tail(dat$date,1) %m+% months(48), by = "month"),
           EPOP = rep(NA, length(month_dates)),
           since_feb20 = rep(NA, length(month_dates)),
           since_now = rep(NA, length(month_dates))) -> future

dat %>% 
  rbind(future) -> dat_fut

row_start_feb20 <- which(grepl(ymd("2020-02-01"), dat_fut$date))
row_start_now <- which(grepl(ymd("2021-11-01"), dat_fut$date)) #edit this


pre_covid_10y_avg <- 0



dat %>% 
  arrange(desc(date)) %>% 
  mutate(epop_chg = EPOP - lead(EPOP,1)) %>% 
  slice(1:12) %>% 
  select(epop_chg) %>% 
  summarize(avg = mean(epop_chg)) %>% 
  unlist() -> last_mths_avg


dat_fut %>% 
  mutate(since_feb20 = case_when(date < ymd("2020-02-01") ~ EPOP,
                                 date >= ymd("2020-02-01") ~ pull(dat[row_start_feb20,"since_feb20"]) + 
                                                          (pre_covid_10y_avg * (row_number() - row_start_feb20))),
         since_now = case_when(date < ymd("2021-11-01") ~ EPOP, #edit this
                              date >= ymd("2021-11-01") ~ pull(dat[row_start_now,"since_now"]) + #edit this
                                                          (last_mths_avg * (row_number() - row_start_now)))) -> df_final



ctitle_1 <- "Prime-age EPOP ratio w/ current trajectory extrapolated"
unit_label <- "%"
source_1 <- "Source: BLS, @benbakkum."

fmt_dcmls <- function(decimals = 0) {
  function(x) as.character(format(round(as.numeric(x), 0), nsmall=0, big.mark=","))
}

df_final %>% 
  pivot_longer(-date, names_to = "key", values_to = "values") %>% 
  mutate(key = case_when(key == "EPOP" ~ "Actual prime-age EPOP",
                         key == "since_feb20" ~ "Pre-pandemic peak",
                         key == "since_now" ~ "Last 12 months trend")) -> df_long #edit this

df_long$key <- factor(df_long$key, c("Pre-pandemic peak",
                                     "Last 12 months trend",
                                     "Actual prime-age EPOP"
                                     ))
                                     
                                     

df_long %>% 
  filter(date > "2017-12-01" & date < "2023-01-01") %>% 
  ggplot(aes(date, values, color = key, linetype = key, size = key)) +
  geom_line(show.legend = F) +
  geom_point(size = 2.5) +
  scale_linetype_manual(values = c("dashed", "dashed", "solid")) +
  scale_color_manual(values = c(cpal("green"), cpal("orange"), cpal("blue"))) +
  scale_size_manual(values = c(1, 1, 1.2)) +
  scale_x_date(expand = c(0,0),
               limits = c(ymd("2018-01-01"), ymd("2023-01-01")),
               date_labels = "'%y",
               date_breaks = "1 year") +
  scale_y_continuous(labels = fmt_dcmls(0)) +
  labs(title = ctitle_1, subtitle = unit_label, caption = source_1) +
  my_theme +
  guides(color=guide_legend(ncol=1),
         linetype=guide_legend(ncol=1)) +
  theme(legend.key.height = unit(0.7, "cm")) +
  guides(colour = guide_legend(override.aes = list(size=7))) +
  transition_reveal(date, keep_last = TRUE) -> chart1




anim1 <- animate(chart1, renderer = gifski_renderer(loop = T), nframe = 250,
                 width = 615, height = 460, type = "cairo", end_pause = 200)

anim1
```

On the inflation side, I look for when the largest declines in year-over-year inflation may occur if things begin to moderate by making a rather large assumption that month-over-month numbers will fall into their average over the last five years (keep in mind I'm showing CPI so the level of PCE, the Fed's target measure, would hypothetically be even lower).

```{r echo=FALSE, warning=FALSE, message = FALSE, tidy=FALSE}
dat <- bls_api(c("CUSR0000SA0", "CUSR0000SA0L1E"), 
              startyear = 2006, 
              endyear = 2021, 
              Sys.getenv("BLS_KEY"))

data.frame(name = c("headline_cpi", "core_cpi"),
           code = c("CUSR0000SA0", "CUSR0000SA0L1E")) -> key

rolling_mean <- rollify(mean, window = 60)

dat %>% 
  mutate(date = paste0(periodName, " ", year, " 01"),
         date = as.Date(date, "%B %Y %d")) %>% 
  rename(code = seriesID) %>% 
  left_join(key, by = "code") %>% 
  select(value, date, name) %>% 
  pivot_wider(names_from = "name", values_from = "value") %>%
  arrange(date) %>% 
  mutate(headline_mm      =  (headline_cpi / lag(headline_cpi, 1) - 1) * 100,
         core_mm          =  (core_cpi / lag(core_cpi, 1) - 1) * 100,
         headline_mm_avg  =   rolling_mean(headline_mm),
         core_mm_avg      =   rolling_mean(core_mm),
         headline_dev     = -(headline_mm - headline_mm_avg),
         core_dev         = -(core_mm - core_mm_avg),
         headline_proj    =   headline_cpi,
         core_proj        =   core_cpi) -> df




x <- nrow(df)
next_month <- ymd(pull(df[,1])) %m+% months(1)
for (i in 1:18) {
  df[x + i,] <- NA
  
  df[x + i,1] <- ymd(pull(df[x + i -1,1])) %m+% months(1)
  
  df$headline_proj[x + i] <- (1 + df$headline_mm_avg[x]/100) * df$headline_proj[x + i - 1]
  
  df$core_proj[x + i] <- (1 + df$core_mm_avg[x]/100) * df$core_proj[x + i - 1]
  
  df$headline_mm_avg[x + i] <- df$headline_mm_avg[x]
  
  df$core_mm_avg[x + i] <- df$core_mm_avg[x]
}

df %>% 
  mutate(headline_dev_lag =   lag(headline_dev,12),
         core_def_lag     =   lag(core_dev,12),
         headline_adj     =   (1 + lag(headline_mm_avg,1)/100) * lag(headline_proj,1),
         core_adj         =   (1 + lag(core_mm_avg,1)/100) * lag(core_proj,1),
         headline_yy      =   ((headline_proj / lag(headline_proj,12) - 1) * 100),
         core_yy          =   ((core_proj / lag(core_proj,12) - 1) * 100),
         headline_yy_adj  =   ((headline_proj / lag(headline_adj,12) - 1) * 100),
         core_yy_adj      =   ((core_proj / lag(core_adj,12) - 1) * 100),
         headline_be      =   headline_yy - headline_yy_adj,
         core_be          =   core_yy - core_yy_adj,
         headline_yy_ex   =   case_when(date < ymd(next_month) ~ NA_real_,
                                        date >= ymd(next_month) ~ headline_yy),
         core_yy_ex       =   case_when(date < ymd(next_month) ~ NA_real_,
                                        date >= ymd(next_month) ~ core_yy),
         headline_yy_act  =   case_when(date >= ymd(next_month) ~ NA_real_,
                                        date < ymd(next_month) ~ headline_yy),
         core_yy_act      =   case_when(date >= ymd(next_month) ~ NA_real_,
                                        date < ymd(next_month) ~ core_yy)) -> df_all 

eight_mths_ago <- ymd(pull(df[x,1])) %m+% months(-8)
five_mths_later <- ymd(pull(df[x,1])) %m+% months(5)
curr_mth <- ymd(pull(df[x,1])) + days(14)
twenty_mths_ago <- ymd(pull(df[x,1])) %m+% months(-20)
sixteen_mths_later <- ymd(pull(df[x,1])) %m+% months(16)

df_all %>% 
  select(date, headline_yy_ex, core_yy_ex) %>% 
  pivot_longer(-date, names_to = "key", values_to = "values") %>%
  mutate(key = case_when(key == "core_yy_ex" ~ "Extrapolated core CPI",
                         key == "headline_yy_ex" ~ "Extrapolated headline CPI"),
         placeholder = "X") %>% 
  filter(date > twenty_mths_ago & date < sixteen_mths_later) -> ex_cht_dat

df_all %>% 
  select(date, headline_yy_act, core_yy_act) %>% 
  pivot_longer(-date, names_to = "key", values_to = "values") %>%
  mutate(key = case_when(key == "core_yy_act" ~ "Core CPI",
                         key == "headline_yy_act" ~ "Headline CPI"),
         placeholder = "X") %>% 
  filter(date > twenty_mths_ago & date < sixteen_mths_later) -> act_cht_dat

ex_cht_dat$key <- factor(ex_cht_dat$key, c("Extrapolated core CPI", "Extrapolated headline CPI"))
act_cht_dat$key <- factor(act_cht_dat$key, c("Core CPI", "Headline CPI"))
        
ctitle_1 <- "Year-over-year CPI extrapolated w/ avg monthly change"
unit_label <- "%, y/y"
source_1 <- "Source: BLS, @benbakkum."

ggplot() +
  geom_step(data = ex_cht_dat, aes(date, values, color = key, linetype = key), size = 1) +
  geom_step(data = act_cht_dat, aes(date, values, color = key, linetype = key), size = 1) +
  scale_color_manual(values = c(cpal("blue"), cpal("blue"), cpal("green"), cpal("green"))) +
  scale_linetype_manual(values = c("solid", "dashed", "dashed", "solid")) +
  scale_y_continuous(breaks = seq(0,5.5, by = 0.5)) +
  scale_x_date(expand = c(0,0), date_breaks = "6 months", date_labels = "%b '%y") +
  geom_vline(xintercept = ymd(curr_mth), linetype = "dashed", color = cpal("border grey"), size = 1) +
  labs(title = ctitle_1, subtitle = unit_label, caption = source_1) +
  my_theme +
  guides(color = guide_legend(ncol = 2, byrow = T,
                              override.aes = list(linetype = c("solid", "twodash", "twodash", "solid"),
                                                  size = 1))) +
  transition_manual(placeholder) -> p

anim1 <- animate(p, renderer = gifski_renderer(loop = T), nframe = 1,
                 width = 615, height = 420, type = "cairo")

anim1

```

If inflation is still quite high next summer, expect the Fed to be ready to hike without a second thought, given they will have already waited for the labor market to catch up and to see if inflationary pressures were a flash in the pan. If the bullwhip effect really comes through in the first half of the year and inflation craters, the Fed will have something close to goldilocks conditions on its hands and will be able to fine tune rates and policy guidance to try to maintain them. 


